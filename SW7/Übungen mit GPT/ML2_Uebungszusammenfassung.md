# ğŸ§  ML2 Praxiszusammenfassung â€“ Hackathon-Vorbereitung

## ğŸ‘¤ Teilnehmer
**Name:** _(bitte selbst ergÃ¤nzen)_  
**Kurs:** Machine Learning 2 (FS 2025)  
**Dozentin:** Dr. Elena Gavagnin

---

## âœ… Ãœberblick: Was wurde geÃ¼bt?

| Ãœbung | Thema |
|-------|-------|
| Ãœ1 | Klassisches MLP-Modell auf MNIST |
| Ãœ2 | Hyperparameter-Experimente |
| Ãœ3 | EMNIST Buchstabenklassifikation |
| Ãœ4 | Modell speichern & laden |
| Ãœ5 | Fehleranalyse & Reflexion |
| Mini-Challenge | Fashion MNIST mit VorhersageprÃ¼fung |

---

## ğŸ§ª Ãœbung 1: MNIST Klassifikation

### âœ… Aufgaben
- Laden & Normalisieren von MNIST
- Einfaches MLP mit 2 Dense-Schichten
- Dropout gegen Overfitting
- EarlyStopping als Callback

### ğŸ§© Codeauszug
```python
model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10, activation='softmax')
])
```

### âš ï¸ Anfangsproblem
- `input_shape=(28, 28, 1)` war falsch fÃ¼r MNIST
- `input_dim` unnÃ¶tig gesetzt â†’ spÃ¤ter entfernt

---

## âš™ï¸ Ãœbung 2: Hyperparameter-Tests

### âœ… Variationen getestet
- Neuronenzahl: 16, 64, 128
- Optimizer: SGD, Adam, RMSprop
- Learning Rate: 0.0001 bis 0.01
- Batch Size: 32 bis 256

### ğŸ§  Erkenntnisse
- Zu kleine Netze + zu kleine LR = schlechtes Lernen
- Adam + 128 Neuronen + 0.001 LR + 64 Batch = ğŸ’¡ sehr stabil

---

## ğŸ”¤ Ãœbung 3: EMNIST Letters

### âœ… Aufgaben
- Datensatz geladen & Labels von 1â€“26 auf 0â€“25 umgewandelt
- Modell mit 256 Neuronen, Dropout, EarlyStopping
- Softmax-Ausgabe mit 26 Klassen

### ğŸ§  Problem gelÃ¶st
- Einzelne Klasse wurde falsch klassifiziert (Q als A)
- Selbst analysiert: Handschrift schwer lesbar, Modell liegt nicht vÃ¶llig falsch

---

## ğŸ’¾ Ãœbung 4: Modell speichern & laden

### âœ… Aufgaben
- Modell mit `model.save()` gespeichert
- Mit `load_model()` neu geladen
- Vorhersagen mit `predict()` gemacht

### ğŸ“Š Beispielcode
```python
model.save("emnist_model.keras")
loaded_model = tf.keras.models.load_model("emnist_model.keras")
```

---

## ğŸ” Ãœbung 5: Fehleranalyse

### ğŸ“Œ Fallbeispiel
- Modell hat 1 Beispiel falsch klassifiziert (A â†” Q)
- Reflexion: Handschrift schwer lesbar, akzeptabler Fehler

---

## ğŸ‘Ÿ Mini-Challenge: Fashion MNIST

### âœ… Aufgaben
- Komplettes Training auf Fashion MNIST
- 5 zufÃ¤llige Vorhersagen inkl. Bilder
- Vergleich Vorhersage vs. echtes Label mit âœ…/âŒ

### ğŸ“¸ Visualisierung
```python
for i in indices:
    img = X_test[i]
    label = y_test[i]
    pred = np.argmax(model.predict(img.reshape(1, 28, 28)))
    status = 'âœ…' if pred == label else 'âŒ'
    plt.imshow(img, cmap="gray")
    plt.title(f"Vorhersage: {class_names[pred]}, Wahr: {class_names[label]} {status}")
    plt.axis("off")
    plt.show()
```

---

## ğŸ§  Reflexion: Wo gabâ€™s MÃ¼he?

| Thema | Herausforderung | GelÃ¶st durch |
|-------|------------------|--------------|
| Input-Shape in Flatten | Klammern zu tief (28, 28, 1) statt (28, 28) | Korrektur nach Hinweis |
| EarlyStopping | Zuerst definiert, aber nicht eingebaut | RÃ¼ckmeldung erhalten |
| Vorhersageausgabe | Falscher Vergleich (`X_train` statt `y_train`) | Codehilfe genutzt |
| `plt.title()`-Syntax | Falsche Platzierung von `if`-Ausdruck | Korrekte Formatierung gezeigt |

---

## ğŸ Fazit

Du hast alle zentralen ML-Konzepte praktisch angewendet:
- Modellierung, Evaluation, Speicherung
- Vorhersage, Visualisierung, Reflexion
- Fehler erkennen und verstehen

---

## ğŸ§­ NÃ¤chste Schritte (geplant)
- [ ] ğŸ“„ Mock-PrÃ¼fung durchfÃ¼hren
- [ ] ğŸ” Wiederholung mit CNN oder Transfer Learning
- [ ] ğŸš€ Eigenes Mini-Projekt mit realen Daten

---
