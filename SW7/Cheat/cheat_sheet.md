# ðŸ§  ML2 Week 7 Cheat Sheet: Artificial Neural Networks (ANNs) & Practice Patterns

## âœ… Key Concepts

- **Artificial Neural Network (ANN)**: Model inspired by biological neurons; consists of layers of nodes (neurons) connected by weights, with activation functions introducing nonlinearity.
- **Perceptron**: Basic neural unit performing weighted sum + activation; works only on linearly separable data.
- **Multilayer Perceptron (MLP)**: Feedforward neural network with multiple hidden layers; allows learning of non-linear patterns.
- **Activation Functions**:
  - Linear: `f(x) = x` â†’ not useful for deep learning.
  - Sigmoid: `Ïƒ(x) = 1 / (1 + e^{-x})` â†’ squashes output between 0â€“1.
  - ReLU: `max(0, x)` â†’ introduces sparsity, accelerates training.
  - Softmax: Converts logits to probabilities over multiple classes.
- **Loss Functions**:
  - BinaryCrossentropy â†’ binary classification.
  - CategoricalCrossentropy â†’ multi-class classification.
  - MeanSquaredError â†’ regression.
- **Optimizers**: Algorithms to update weights: SGD, Momentum, RMSProp, Adam.
- **Regularization**: Techniques (L1/L2 penalties, dropout) to prevent overfitting.
- **Hyperparameters**: Settings like learning rate, batch size, epochs, layer sizes (not learned from data).

---

## âœ… Typical Task Patterns

### ðŸ”¹ 1. Build and Compile a Model
```python
import tensorflow as tf

model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_dim=784),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

### ðŸ”¹ 2. Training Loop
```python
history = model.fit(
    X_train, y_train,
    epochs=10,
    batch_size=64,
    validation_data=(X_val, y_val)
)
```

### ðŸ”¹ 3. Evaluation and Inference
```python
test_loss, test_acc = model.evaluate(X_test, y_test)
predictions = model.predict(X_new)
```

### ðŸ”¹ 4. Hyperparameter Tuning
```python
from kerastuner import RandomSearch

tuner = RandomSearch(
    build_model_fn,
    objective='val_accuracy',
    max_trials=10,
    directory='my_dir'
)

tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))
```

### ðŸ”¹ 5. Regularization Techniques
```python
tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))
tf.keras.layers.Dropout(0.5)
```

---

## âœ… Relevant Libraries & Frameworks

| Purpose                     | Library             |
|-----------------------------|---------------------|
| Core NN framework           | TensorFlow, Keras   |
| Alternative framework       | PyTorch             |
| Hyperparameter tuning       | Keras Tuner, Hyperopt |
| Data handling               | NumPy, Pandas       |
| Image processing (if needed)| OpenCV, PIL         |
| Visualization               | Matplotlib, TensorBoard |

---

## âœ… Best Practices & Common Pitfalls

- âœ… Set random seeds for reproducibility (`tf.random.set_seed(42)`).
- âœ… Normalize/scale input data (e.g., divide pixel values by 255).
- âœ… Check input/output shapes (especially with `Flatten()` or convolutions).
- âœ… Use early stopping or model checkpoints to prevent overfitting.
- âœ… Monitor both training and validation metrics.
- âœ… Avoid too high learning rates â†’ divergence.
- âœ… Avoid too small learning rates â†’ very slow convergence.
- âœ… Check class balance â†’ accuracy might be misleading if imbalanced.

---

## âœ… Recommended Hyperparameters

| Hyperparameter       | Typical Range/Value          |
|----------------------|-----------------------------|
| Learning rate        | 0.001â€“0.01 (Adam), 0.1â€“1 (SGD) |
| Batch size          | 32, 64, 128                 |
| Epochs              | 10â€“50 (watch for overfit)   |
| Dropout rate        | 0.2â€“0.5                    |
| Optimizer           | Adam (default), SGD + momentum for experimentation |

---

## âœ… Final Checklist: Have You Checked Everything?

âœ… Is CUDA enabled if using GPU?  
âœ… Are random seeds set for reproducibility?  
âœ… Are data shapes (input/output) correctly matched?  
âœ… Did you split data into train, validation, and test?  
âœ… Are loss functions and metrics appropriate for your task (classification vs regression)?  
âœ… Did you monitor learning curves (loss/accuracy) over epochs?  
âœ… Did you save model checkpoints or the final model?  
âœ… Did you test your model on unseen data?

---
